{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('5year.csv',na_values='?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.rename(columns={'class':'bankrupt'})\n",
    "# Å»mijewski's model consists of 3 independent variables:\n",
    "# Attr1 = (net profit / total assets)\n",
    "# Attr2 = (total liabilities / total assets)\n",
    "# Attr4 = (current assets / short-term liabilities)\n",
    "dfz=df[['Attr1','Attr2','Attr4','bankrupt']].copy()\n",
    "dfz=dfz.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# winsorizing the outliers\n",
    "from scipy.stats.mstats import winsorize\n",
    "dfz['Attr1_win']=np.array(winsorize(dfz['Attr1'],limits=[0.05,0.05]))\n",
    "dfz['Attr2_win']=np.array(winsorize(dfz['Attr2'],limits=[0.05,0.05]))\n",
    "dfz['Attr4_win']=np.array(winsorize(dfz['Attr4'],limits=[0.05,0.05]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding polynomials\n",
    "for j in dfz.columns:\n",
    "    if j != 'bankrupt':\n",
    "        for i in [2,3]: \n",
    "                dfz[j+'_'+str(i)]=np.power(dfz[j],i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "# class for making every possible combination of polynomials\n",
    "class VariableCombos:\n",
    "    def __init__(self,include_empty=False):\n",
    "        self.include_empty=include_empty\n",
    "    def make_combos(self,variables):\n",
    "        self.combos=[]\n",
    "        if not self.include_empty:\n",
    "            for i in range(1,len(variables)+1):\n",
    "                for j in combinations(variables,i):\n",
    "                    self.combos.append(list(j))\n",
    "        else:\n",
    "            for i in range(0,len(variables)+1):\n",
    "                for j in combinations(variables,i):\n",
    "                    self.combos.append(list(j))\n",
    "        return self.combos\n",
    "# function for making every possible pair of two variables (interactions)\n",
    "def make_pairs(variables):\n",
    "    pairs=[]\n",
    "    for i in combinations(variables,2):\n",
    "        pairs.append(f'{list(i)[0]}*{list(i)[1]}')\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score,confusion_matrix,jaccard_score,balanced_accuracy_score,roc_auc_score\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "# metrics which should be the best for measuring the performance of the model\n",
    "# the datasdet is imbalanced - the positives (bankruptcies) are less than 7% of all observations\n",
    "# f1 = 2TP/(2TP+FP+FN)\n",
    "# jaccard = TP/(TP+FP+FN)\n",
    "# youden's j statistic = balanced_accuracy_score(adjusted=True) = TP/(TP+FN) + TN/(TN+FP) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vc=VariableCombos(include_empty=True)\n",
    "# making a list of every possible variant of the base model + interactions\n",
    "for i in make_pairs(['Attr1_win','Attr2_win','Attr4_win']):\n",
    "    dfz[i]=dfz[i.split('*')[0]]*dfz[i.split('*')[1]]\n",
    "poly_vars_win_z_interactions=vc.make_combos(make_pairs(['Attr1_win','Attr2_win','Attr4_win']))\n",
    "for i in range(0,len(poly_vars_win_z_interactions)):\n",
    "    poly_vars_win_z_interactions[i]=['Attr1_win','Attr2_win','Attr4_win']+poly_vars_win_z_interactions[i]\n",
    "# making a list of every possible variant of base model + polynomials\n",
    "poly_vars_win_z=vc.make_combos(['Attr1_win_2', 'Attr1_win_3', 'Attr2_win_2', 'Attr2_win_3', 'Attr4_win_2','Attr4_win_3'])\n",
    "for i in range(0,len(poly_vars_win_z)):\n",
    "    poly_vars_win_z[i]=['Attr1_win','Attr2_win','Attr4_win']+poly_vars_win_z[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# polynomials: normal logistic regression\n",
    "X=dfz.drop('bankrupt',axis=1).copy()\n",
    "y=dfz['bankrupt'].copy()\n",
    "# creating the results dataframe\n",
    "dfz_win_results=pd.DataFrame(columns=['variables','best_f1_count','sum_f1','best_gmean_count','sum_gmean','best_jaccard_count','sum_jaccard',\n",
    "                                      'best_tpr_count','sum_tpr','best_youden_count','sum_youden','best_roc_auc_count','sum_roc_auc'])\n",
    "dfz_win_results['variables']=poly_vars_win_z\n",
    "dfz_win_results['variables']=dfz_win_results['variables'].astype(str)\n",
    "dfz_win_results[['best_f1_count','sum_f1','best_gmean_count','sum_gmean','best_jaccard_count','sum_jaccard',\n",
    "                 'best_tpr_count','sum_tpr','best_youden_count','sum_youden','best_roc_auc_count','sum_roc_auc']]=0\n",
    "# best_metric_count = amount of times out of all different train-test splits when a given model had the highest score\n",
    "# sum_metric = sum of every score\n",
    "# prediction thresholds: if (probability of being 1) >= threshold: y_pred=1 else: y_pred=0\n",
    "thresholds=list(np.arange(0.05,1,0.05).round(2))\n",
    "# testing for 19 differnet prediction thresholds, as the standard 50% isn't the only one that can be used\n",
    "# creating a list of resulkts dataframes for different thresholds\n",
    "results_df=[]\n",
    "for i in thresholds:\n",
    "    results_df.append(dfz_win_results.copy())\n",
    "for j in range(0,1000): \n",
    "    # 1000 different train-test splits\n",
    "    X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,stratify=y,random_state=j) \n",
    "    best_f1=[[0,-1] for x in range(0,len(thresholds))]\n",
    "    best_gmean=[[0,-1] for x in range(0,len(thresholds))]\n",
    "    best_jaccard=[[0,-1] for x in range(0,len(thresholds))] \n",
    "    best_tpr=[[0,-1] for x in range(0,len(thresholds))]\n",
    "    best_youden=[[0,-1] for x in range(0,len(thresholds))]\n",
    "    best_roc_auc=[[0,-1] for x in range(0,len(thresholds))]\n",
    "    for i in poly_vars_win_z:\n",
    "        mod=LogisticRegression(max_iter=1000,solver='newton-cholesky',penalty=None,n_jobs=-1).fit(X_train[i],y_train)\n",
    "        # newton-cholesky solver is fast (preferred for n_samples>>n_features), always converges and doesn't require the random_state data shuffling\n",
    "        for k in range(0,len(thresholds)):\n",
    "            # calculating the different metrics\n",
    "            y_pred=(mod.predict_proba(X_test[i])[:,1]>=thresholds[k]).astype(int)\n",
    "            f1=f1_score(y_test,y_pred)  \n",
    "            results_df[k].at[poly_vars_win_z.index(i),'sum_f1']+=f1\n",
    "            gmean=geometric_mean_score(y_test,y_pred)\n",
    "            results_df[k].at[poly_vars_win_z.index(i),'sum_gmean']+=gmean\n",
    "            jaccard=jaccard_score(y_test,y_pred)\n",
    "            results_df[k].at[poly_vars_win_z.index(i),'sum_jaccard']+=jaccard\n",
    "            conf_m=confusion_matrix(y_test,y_pred)\n",
    "            tpr=conf_m[1][1]/(conf_m[1][1]+conf_m[1][0])\n",
    "            results_df[k].at[poly_vars_win_z.index(i),'sum_tpr']+=tpr\n",
    "            youden=balanced_accuracy_score(y_test,y_pred,adjusted=True)\n",
    "            results_df[k].at[poly_vars_win_z.index(i),'sum_youden']+=youden\n",
    "            roc_auc=roc_auc_score(y_test,y_pred)\n",
    "            results_df[k].at[poly_vars_win_z.index(i),'sum_roc_auc']+=roc_auc\n",
    "            # the metrics which enter the final scoreboard are chosen like this\n",
    "            # if a model is having the highest given metric on a given train-test split:\n",
    "            # best_given_metric_count+=1\n",
    "            # for every model:\n",
    "            # given_metric_sum+=given_metric\n",
    "            for l in [[f1,best_f1],[gmean,best_gmean],[jaccard,best_jaccard],[tpr,best_tpr],[youden,best_youden],[roc_auc,best_roc_auc]]:\n",
    "                if l[0]>l[1][k][0]:\n",
    "                    l[1][k][0]=l[0]\n",
    "                    l[1][k][1]=poly_vars_win_z.index(i)\n",
    "    for m in [(best_f1,'best_f1_count'),(best_gmean,'best_gmean_count'),(best_jaccard,'best_jaccard_count'),\n",
    "              (best_tpr,'best_tpr_count'),(best_youden,'best_youden_count'),(best_roc_auc,'best_roc_auc_count')]:\n",
    "       for n in range(0,len(thresholds)):\n",
    "           if m[0][n][1]!=-1:\n",
    "               results_df[n].at[m[0][n][1],m[1]]+=1 \n",
    "# writing the results      \n",
    "for i in thresholds:\n",
    "    results_df[thresholds.index(i)].to_csv(f\"/results_z_win/threshold({format(i,'.2f').replace('.',',')}).csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# polynomials: weighted logistic regression\n",
    "X=dfz.drop('bankrupt',axis=1).copy()\n",
    "y=dfz['bankrupt'].copy()\n",
    "dfz_win_results=pd.DataFrame(columns=['variables','best_f1_count','sum_f1','best_gmean_count','sum_gmean','best_jaccard_count','sum_jaccard',\n",
    "                                      'best_tpr_count','sum_tpr','best_youden_count','sum_youden','best_roc_auc_count','sum_roc_auc'])\n",
    "dfz_win_results['variables']=poly_vars_win_z\n",
    "dfz_win_results['variables']=dfz_win_results['variables'].astype(str)\n",
    "dfz_win_results[['best_f1_count','sum_f1','best_gmean_count','sum_gmean','best_jaccard_count','sum_jaccard',\n",
    "                 'best_tpr_count','sum_tpr','best_youden_count','sum_youden','best_roc_auc_count','sum_roc_auc']]=0\n",
    "results_df=[]\n",
    "thresholds=list(np.arange(0.05,1,0.05).round(2))\n",
    "for i in thresholds:\n",
    "    results_df.append(dfz_win_results.copy())\n",
    "for j in range(0,1000):\n",
    "    X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,stratify=y,random_state=j)\n",
    "    best_f1=[[0,-1] for x in range(0,len(thresholds))]\n",
    "    best_gmean=[[0,-1] for x in range(0,len(thresholds))]\n",
    "    best_jaccard=[[0,-1] for x in range(0,len(thresholds))]\n",
    "    best_tpr=[[0,-1] for x in range(0,len(thresholds))]\n",
    "    best_youden=[[0,-1] for x in range(0,len(thresholds))]\n",
    "    best_roc_auc=[[0,-1] for x in range(0,len(thresholds))]\n",
    "    for i in poly_vars_win_z:\n",
    "        mod=LogisticRegression(max_iter=1000,solver='newton-cholesky',penalty=None,class_weight='balanced',n_jobs=-1).fit(X_train[i],y_train)\n",
    "        for k in range(0,len(thresholds)):\n",
    "            y_pred=(mod.predict_proba(X_test[i])[:,1]>=thresholds[k]).astype(int)\n",
    "            f1=f1_score(y_test,y_pred)  \n",
    "            results_df[k].at[poly_vars_win_z.index(i),'sum_f1']+=f1\n",
    "            gmean=geometric_mean_score(y_test,y_pred)\n",
    "            results_df[k].at[poly_vars_win_z.index(i),'sum_gmean']+=gmean\n",
    "            jaccard=jaccard_score(y_test,y_pred)\n",
    "            results_df[k].at[poly_vars_win_z.index(i),'sum_jaccard']+=jaccard\n",
    "            conf_m=confusion_matrix(y_test,y_pred)\n",
    "            tpr=conf_m[1][1]/(conf_m[1][1]+conf_m[1][0])\n",
    "            results_df[k].at[poly_vars_win_z.index(i),'sum_tpr']+=tpr\n",
    "            youden=balanced_accuracy_score(y_test,y_pred,adjusted=True)\n",
    "            results_df[k].at[poly_vars_win_z.index(i),'sum_youden']+=youden\n",
    "            roc_auc=roc_auc_score(y_test,y_pred)\n",
    "            results_df[k].at[poly_vars_win_z.index(i),'sum_roc_auc']+=roc_auc\n",
    "            for l in [[f1,best_f1],[gmean,best_gmean],[jaccard,best_jaccard],[tpr,best_tpr],[youden,best_youden],[roc_auc,best_roc_auc]]:\n",
    "                if l[0]>l[1][k][0]:\n",
    "                    l[1][k][0]=l[0]\n",
    "                    l[1][k][1]=poly_vars_win_z.index(i)\n",
    "    for m in [(best_f1,'best_f1_count'),(best_gmean,'best_gmean_count'),(best_jaccard,'best_jaccard_count'),\n",
    "              (best_tpr,'best_tpr_count'),(best_youden,'best_youden_count'),(best_roc_auc,'best_roc_auc_count')]:\n",
    "       for n in range(0,len(thresholds)):\n",
    "           if m[0][n][1]!=-1:\n",
    "               results_df[n].at[m[0][n][1],m[1]]+=1       \n",
    "for i in thresholds:\n",
    "    results_df[thresholds.index(i)].to_csv(f\"/results_z_win_weighted/threshold({format(i,'.2f').replace('.',',')}).csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interactions: normal logistic regression\n",
    "X=dfz.drop('bankrupt',axis=1).copy()\n",
    "y=dfz['bankrupt'].copy()\n",
    "dfz_win_results=pd.DataFrame(columns=['variables','best_f1_count','sum_f1','best_gmean_count','sum_gmean','best_jaccard_count','sum_jaccard',\n",
    "                                      'best_tpr_count','sum_tpr','best_youden_count','sum_youden','best_roc_auc_count','sum_roc_auc'])\n",
    "dfz_win_results['variables']=poly_vars_win_z_interactions\n",
    "dfz_win_results['variables']=dfz_win_results['variables'].astype(str)\n",
    "dfz_win_results[['best_f1_count','sum_f1','best_gmean_count','sum_gmean','best_jaccard_count','sum_jaccard',\n",
    "                 'best_tpr_count','sum_tpr','best_youden_count','sum_youden','best_roc_auc_count','sum_roc_auc']]=0\n",
    "results_df=[]\n",
    "thresholds=list(np.arange(0.05,1,0.05).round(2))\n",
    "for i in thresholds:\n",
    "    results_df.append(dfz_win_results.copy())\n",
    "for j in range(0,1000):\n",
    "    X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,stratify=y,random_state=j,n_jobs=-1)\n",
    "    best_f1=[[0,-1] for x in range(0,len(thresholds))]\n",
    "    best_gmean=[[0,-1] for x in range(0,len(thresholds))]\n",
    "    best_jaccard=[[0,-1] for x in range(0,len(thresholds))]\n",
    "    best_tpr=[[0,-1] for x in range(0,len(thresholds))]\n",
    "    best_youden=[[0,-1] for x in range(0,len(thresholds))]\n",
    "    best_roc_auc=[[0,-1] for x in range(0,len(thresholds))]\n",
    "    for i in poly_vars_win_z_interactions:\n",
    "        mod=LogisticRegression(max_iter=1000,solver='newton-cholesky',penalty=None).fit(X_train[i],y_train)\n",
    "        for k in range(0,len(thresholds)):\n",
    "            y_pred=(mod.predict_proba(X_test[i])[:,1]>=thresholds[k]).astype(int)\n",
    "            f1=f1_score(y_test,y_pred)  \n",
    "            results_df[k].at[poly_vars_win_z_interactions.index(i),'sum_f1']+=f1\n",
    "            gmean=geometric_mean_score(y_test,y_pred)\n",
    "            results_df[k].at[poly_vars_win_z_interactions.index(i),'sum_gmean']+=gmean\n",
    "            jaccard=jaccard_score(y_test,y_pred)\n",
    "            results_df[k].at[poly_vars_win_z_interactions.index(i),'sum_jaccard']+=jaccard\n",
    "            conf_m=confusion_matrix(y_test,y_pred)\n",
    "            tpr=conf_m[1][1]/(conf_m[1][1]+conf_m[1][0])\n",
    "            results_df[k].at[poly_vars_win_z_interactions.index(i),'sum_tpr']+=tpr\n",
    "            youden=balanced_accuracy_score(y_test,y_pred,adjusted=True)\n",
    "            results_df[k].at[poly_vars_win_z_interactions.index(i),'sum_youden']+=youden\n",
    "            roc_auc=roc_auc_score(y_test,y_pred)\n",
    "            results_df[k].at[poly_vars_win_z_interactions.index(i),'sum_roc_auc']+=roc_auc\n",
    "            for l in [[f1,best_f1],[gmean,best_gmean],[jaccard,best_jaccard],[tpr,best_tpr],[youden,best_youden],[roc_auc,best_roc_auc]]:\n",
    "                if l[0]>l[1][k][0]:\n",
    "                    l[1][k][0]=l[0]\n",
    "                    l[1][k][1]=poly_vars_win_z_interactions.index(i)\n",
    "    for m in [(best_f1,'best_f1_count'),(best_gmean,'best_gmean_count'),(best_jaccard,'best_jaccard_count'),\n",
    "              (best_tpr,'best_tpr_count'),(best_youden,'best_youden_count'),(best_roc_auc,'best_roc_auc_count')]:\n",
    "       for n in range(0,len(thresholds)):\n",
    "           if m[0][n][1]!=-1:\n",
    "               results_df[n].at[m[0][n][1],m[1]]+=1       \n",
    "for i in thresholds:\n",
    "    results_df[thresholds.index(i)].to_csv(f\"/results_z_win_interactions/threshold({format(i,'.2f').replace('.',',')}).csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interactions: weighted logsistic regression\n",
    "X=dfz.drop('bankrupt',axis=1).copy()\n",
    "y=dfz['bankrupt'].copy()\n",
    "dfz_win_results=pd.DataFrame(columns=['variables','best_f1_count','sum_f1','best_gmean_count','sum_gmean','best_jaccard_count','sum_jaccard',\n",
    "                                      'best_tpr_count','sum_tpr','best_youden_count','sum_youden','best_roc_auc_count','sum_roc_auc'])\n",
    "dfz_win_results['variables']=poly_vars_win_z_interactions\n",
    "dfz_win_results['variables']=dfz_win_results['variables'].astype(str)\n",
    "dfz_win_results[['best_f1_count','sum_f1','best_gmean_count','sum_gmean','best_jaccard_count','sum_jaccard',\n",
    "                 'best_tpr_count','sum_tpr','best_youden_count','sum_youden','best_roc_auc_count','sum_roc_auc']]=0\n",
    "results_df=[]\n",
    "thresholds=list(np.arange(0.05,1,0.05).round(2))\n",
    "for i in thresholds:\n",
    "    results_df.append(dfz_win_results.copy())\n",
    "for j in range(0,1000):\n",
    "    X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,stratify=y,random_state=j,n_jobs=-1)\n",
    "    best_f1=[[0,-1] for x in range(0,len(thresholds))]\n",
    "    best_gmean=[[0,-1] for x in range(0,len(thresholds))]\n",
    "    best_jaccard=[[0,-1] for x in range(0,len(thresholds))]\n",
    "    best_tpr=[[0,-1] for x in range(0,len(thresholds))]\n",
    "    best_youden=[[0,-1] for x in range(0,len(thresholds))]\n",
    "    best_roc_auc=[[0,-1] for x in range(0,len(thresholds))]\n",
    "    for i in poly_vars_win_z_interactions:\n",
    "        mod=LogisticRegression(max_iter=1000,solver='newton-cholesky',penalty=None,class_weight='balanced').fit(X_train[i],y_train)\n",
    "        for k in range(0,len(thresholds)):\n",
    "            y_pred=(mod.predict_proba(X_test[i])[:,1]>=thresholds[k]).astype(int)\n",
    "            f1=f1_score(y_test,y_pred)  \n",
    "            results_df[k].at[poly_vars_win_z_interactions.index(i),'sum_f1']+=f1\n",
    "            gmean=geometric_mean_score(y_test,y_pred)\n",
    "            results_df[k].at[poly_vars_win_z_interactions.index(i),'sum_gmean']+=gmean\n",
    "            jaccard=jaccard_score(y_test,y_pred)\n",
    "            results_df[k].at[poly_vars_win_z_interactions.index(i),'sum_jaccard']+=jaccard\n",
    "            conf_m=confusion_matrix(y_test,y_pred)\n",
    "            tpr=conf_m[1][1]/(conf_m[1][1]+conf_m[1][0])\n",
    "            results_df[k].at[poly_vars_win_z_interactions.index(i),'sum_tpr']+=tpr\n",
    "            youden=balanced_accuracy_score(y_test,y_pred,adjusted=True)\n",
    "            results_df[k].at[poly_vars_win_z_interactions.index(i),'sum_youden']+=youden\n",
    "            roc_auc=roc_auc_score(y_test,y_pred)\n",
    "            results_df[k].at[poly_vars_win_z_interactions.index(i),'sum_roc_auc']+=roc_auc\n",
    "            for l in [[f1,best_f1],[gmean,best_gmean],[jaccard,best_jaccard],[tpr,best_tpr],[youden,best_youden],[roc_auc,best_roc_auc]]:\n",
    "                if l[0]>l[1][k][0]:\n",
    "                    l[1][k][0]=l[0]\n",
    "                    l[1][k][1]=poly_vars_win_z_interactions.index(i)\n",
    "    for m in [(best_f1,'best_f1_count'),(best_gmean,'best_gmean_count'),(best_jaccard,'best_jaccard_count'),\n",
    "              (best_tpr,'best_tpr_count'),(best_youden,'best_youden_count'),(best_roc_auc,'best_roc_auc_count')]:\n",
    "       for n in range(0,len(thresholds)):\n",
    "           if m[0][n][1]!=-1:\n",
    "               results_df[n].at[m[0][n][1],m[1]]+=1       \n",
    "for i in thresholds:\n",
    "    results_df[thresholds.index(i)].to_csv(f\"/results_z_win_interactions_weighted/threshold({format(i,'.2f').replace('.',',')}).csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# balanced random forest classifier on the base model\n",
    "# creating a random forest model to see how it performs in comparision to the different logistic regressions\n",
    "X=dfz.drop('bankrupt',axis=1).copy()\n",
    "y=dfz['bankrupt'].copy()\n",
    "dfz_win_results=pd.DataFrame(columns=['variables','best_f1_count','sum_f1','best_gmean_count','sum_gmean','best_jaccard_count','sum_jaccard',\n",
    "                                      'best_tpr_count','sum_tpr','best_youden_count','sum_youden','best_roc_auc_count','sum_roc_auc'])\n",
    "dfz_win_results['variables']=[['Attr1_win','Attr2_win','Attr4_win']]\n",
    "dfz_win_results['variables']=dfz_win_results['variables'].astype(str)\n",
    "dfz_win_results[['best_f1_count','sum_f1','best_gmean_count','sum_gmean','best_jaccard_count','sum_jaccard',\n",
    "                 'best_tpr_count','sum_tpr','best_youden_count','sum_youden','best_roc_auc_count','sum_roc_auc']]=0\n",
    "results_df=[]\n",
    "thresholds=list(np.arange(0.05,1,0.05).round(2))\n",
    "# This^ is the reason why I chose random forest - it can predict_proba\n",
    "# when it comes to the majority vote, the probability of y being bankrupt can be calculated as follows: \n",
    "# (amount of decision trees voting bankrupt)/(total amount of decision trees in the random forest)\n",
    "for i in thresholds:\n",
    "    results_df.append(dfz_win_results.copy())\n",
    "for j in range(0,1000):\n",
    "    X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,stratify=y,random_state=j)\n",
    "    best_f1=[[0,-1] for x in range(0,len(thresholds))]\n",
    "    best_gmean=[[0,-1] for x in range(0,len(thresholds))]\n",
    "    best_jaccard=[[0,-1] for x in range(0,len(thresholds))]\n",
    "    best_tpr=[[0,-1] for x in range(0,len(thresholds))]\n",
    "    best_youden=[[0,-1] for x in range(0,len(thresholds))]\n",
    "    best_roc_auc=[[0,-1] for x in range(0,len(thresholds))]\n",
    "    for i in [['Attr1_win','Attr2_win','Attr4_win']]:\n",
    "        mod=RandomForestClassifier(n_estimators=100,max_features=None,max_depth=5,min_weight_fraction_leaf=0.2,class_weight='balanced',random_state=2812,n_jobs=-1).fit(X_train[i],y_train)\n",
    "        # min_fraction_leaf=0.2 seems to yield best results. This value was chosen out of arange(0.05,1,0.05)\n",
    "        for k in range(0,len(thresholds)):\n",
    "            y_pred=(mod.predict_proba(X_test[i])[:,1]>=thresholds[k]).astype(int)\n",
    "            f1=f1_score(y_test,y_pred)  \n",
    "            results_df[k].at[0,'sum_f1']+=f1\n",
    "            gmean=geometric_mean_score(y_test,y_pred)\n",
    "            results_df[k].at[0,'sum_gmean']+=gmean\n",
    "            jaccard=jaccard_score(y_test,y_pred)\n",
    "            results_df[k].at[0,'sum_jaccard']+=jaccard\n",
    "            conf_m=confusion_matrix(y_test,y_pred)\n",
    "            tpr=conf_m[1][1]/(conf_m[1][1]+conf_m[1][0])\n",
    "            results_df[k].at[0,'sum_tpr']+=tpr\n",
    "            youden=balanced_accuracy_score(y_test,y_pred,adjusted=True)\n",
    "            results_df[k].at[0,'sum_youden']+=youden\n",
    "            roc_auc=roc_auc_score(y_test,y_pred)\n",
    "            results_df[k].at[0,'sum_roc_auc']+=roc_auc\n",
    "            for l in [[f1,best_f1],[gmean,best_gmean],[jaccard,best_jaccard],[tpr,best_tpr],[youden,best_youden],[roc_auc,best_roc_auc]]:\n",
    "                if l[0]>l[1][k][0]:\n",
    "                    l[1][k][0]=l[0]\n",
    "                    l[1][k][1]=0\n",
    "    for m in [(best_f1,'best_f1_count'),(best_gmean,'best_gmean_count'),(best_jaccard,'best_jaccard_count'),\n",
    "              (best_tpr,'best_tpr_count'),(best_youden,'best_youden_count'),(best_roc_auc,'best_roc_auc_count')]:\n",
    "       for n in range(0,len(thresholds)):\n",
    "           if m[0][n][1]!=-1:\n",
    "               results_df[n].at[m[0][n][1],m[1]]+=1       \n",
    "for i in thresholds:\n",
    "    results_df[thresholds.index(i)].to_csv(f\"/results_z_win_random_forest/threshold({format(i,'.2f').replace('.',',')}).csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b5a5863c6484440c6c6336a69251c3f06aad36785994906f72e73a0e599fa43f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
